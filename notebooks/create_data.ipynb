{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# data_path = 'node.dat'\n",
    "# nodes = pd.read_csv(data_path, header=None, sep='\\t')\n",
    "\n",
    "# # 假设文件列顺序为：ID, Name, Type, Feature\n",
    "# nodes.columns = ['id', 'name', 'type', 'feature']\n",
    "\n",
    "# # 创建一个新的列 'new_id' 用于存储每种类型从零开始的编号\n",
    "# nodes['new_id'] = nodes.groupby('type').cumcount()\n",
    "\n",
    "# # 查看结果\n",
    "# print(nodes.head())\n",
    "\n",
    "# # 保存新的node文件，如果需要的话\n",
    "# nodes.to_csv('node_with_new_id.dat', sep='\\t', index=False, header=False)\n",
    "\n",
    "data_path = Path.cwd().parent.joinpath('data/bp/node.dat')\n",
    "\n",
    "nodes = pd.read_csv(data_path, header=None, sep='\\t')\n",
    "nodes.columns = ['id', 'name', 'type', 'feature']\n",
    "nodes['new_id'] = nodes.groupby('type').cumcount()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.loc[nodes['type'] == 1, 'feature'] = None\n",
    "# output_path = Path.cwd().parent.joinpath('dataset/bp/node.dat')\n",
    "# nodes.to_csv(output_path, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取节点文件，并创建原始ID到新ID的映射字典\n",
    "# nodes_path = 'node_with_new_id_and_modified_feature.dat'  # 节点文件路径\n",
    "# data_path = Path.cwd().parent.joinpath('data/bp/node.dat')\n",
    "# nodes = pd.read_csv(data_path, header=None, sep='\\t')\n",
    "nodes.columns = ['id', 'name', 'type', 'feature', 'new_id']\n",
    "\n",
    "# 创建一个字典映射，用于快速查找\n",
    "id_to_new_id = nodes.set_index('id')['new_id'].to_dict()\n",
    "id_to_type = nodes.set_index('id')['type'].to_dict()\n",
    "\n",
    "# 读取link文件\n",
    "link_path = Path.cwd().parent.joinpath('data/bp/link.dat')  # 请将其改为你的link文件路径\n",
    "links = pd.read_csv(link_path, header=None, sep='\\t')\n",
    "links.columns = ['id1', 'id2', 'type', 'score']\n",
    "\n",
    "# 定义函数用于根据类型来更新id1和id2\n",
    "def update_id(row):\n",
    "    type1 = id_to_type[row['id1']]\n",
    "    type2 = id_to_type[row['id2']]\n",
    "    if row['type'] == 0:  # 类别0的节点-类别1的节点\n",
    "        if type1 == 0 and type2 == 1:\n",
    "            row['id1'] = id_to_new_id[row['id1']]\n",
    "            row['id2'] = id_to_new_id[row['id2']]\n",
    "    elif row['type'] == 1:  # 类别0-类别0\n",
    "        if type1 == 0 and type2 == 0:\n",
    "            row['id1'] = id_to_new_id[row['id1']]\n",
    "            row['id2'] = id_to_new_id[row['id2']]\n",
    "    elif row['type'] == 2:  # 类别1-类别1\n",
    "        if type1 == 1 and type2 == 1:\n",
    "            row['id1'] = id_to_new_id[row['id1']]\n",
    "            row['id2'] = id_to_new_id[row['id2']]\n",
    "    return row\n",
    "\n",
    "# 更新link文件中的id1和id2\n",
    "links = links.apply(update_id, axis=1)\n",
    "\n",
    "links[['id1', 'id2', 'type']] = links[['id1', 'id2', 'type']].astype(int)\n",
    "# 保存更新后的link数据到新文件\n",
    "output_link_path = Path.cwd().parent.joinpath('dataset/bp/updated_link.dat')  # 目标文件路径\n",
    "links.to_csv(output_link_path, sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
